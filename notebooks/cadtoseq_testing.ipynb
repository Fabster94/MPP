{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2365fdd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, multilabel_confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#custom imports\n",
    "from mpp.ml.models.sequence.vecset_transformer import ARMSTD\n",
    "from mpp.constants import PATHS, VOCAB, INV_VOCAB\n",
    "from mpp.ml.models.classifier.cadtostepset import ProcessClassificationTrsfmEncoderModule\n",
    "from mpp.ml.datasets.fabricad import Fabricad\n",
    "from mpp.ml.datasets.tkms import TKMS_Process_Dataset\n",
    "from mpp.ml.datasets.datamodules import collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f21476",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#set random seed for reproducibility\n",
    "random.seed(42)\n",
    "# Set the random seed for PyTorch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#checkpoint_path = Path(\"/home/michelkruse/repos/cadtoseq/outputs/cadtoseq/2025-05-06-09:50:25_None/lightning_logs/version_0/checkpoints/epoch=943-val_loss=0.4672.ckpt\")\n",
    "checkpoint_path = Path(\"/workspace/mpp/src/cadtoseq/ml/models/checkpoints/best_model/cadtostepset/cadtostepset-best-epoch=66-val_loss=0.4306.ckpt\")\n",
    "\n",
    "model = ProcessClassificationTrsfmEncoderModule.load_from_checkpoint(checkpoint_path=checkpoint_path.as_posix())\n",
    "model = model.to(\"cuda\")\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c540b60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TKMS_Process_Dataset(mode=\"test\")\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=58, shuffle=False) #SHUFFLE False for eva with filenames\n",
    "v, p = next(iter(test_loader))\n",
    "\n",
    "print(f\"Vector shape: {v.shape}\")\n",
    "print(f\"Label shape: {p.shape}\")\n",
    "print(f\"Label example: {p[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969de23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "v, p = next(iter(test_loader))\n",
    "v = v.to(device)\n",
    "p = p.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(v)\n",
    "    print(f\"Model output shape: {outputs.shape}\")\n",
    "    print(f\"Output example: {outputs[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdacd20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = ['Bohren', 'Drehen', 'Fräsen']\n",
    "\n",
    "# Evaluation loop\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "threshold = 0.5\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        vec_sets, labels = batch\n",
    "        vec_sets = vec_sets.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = model(vec_sets)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert to binary predictions\n",
    "        predictions = (probs > threshold).float()\n",
    "        \n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate all batches\n",
    "all_predictions = np.vstack(all_predictions)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_micro = f1_score(all_labels, all_predictions, average='micro')\n",
    "f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "f1_per_class = f1_score(all_labels, all_predictions, average=None)\n",
    "\n",
    "print(f\"F1 Score (Micro): {f1_micro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(\"\\nF1 Score per class:\")\n",
    "for name, score in zip(class_names, f1_per_class):\n",
    "    print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, \n",
    "                          target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03c466",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Multi-label confusion matrices (one per class)\n",
    "cm_per_class = multilabel_confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Plot confusion matrix for each class\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for idx, (cm, class_name) in enumerate(zip(cm_per_class, class_names)):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "    axes[idx].set_title(f'Confusion Matrix: {class_name}')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "    axes[idx].set_xticklabels(['No', 'Yes'])\n",
    "    axes[idx].set_yticklabels(['No', 'Yes'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix details\n",
    "for class_name, cm in zip(class_names, cm_per_class):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  True Positives: {tp}\")\n",
    "    print(f\"  False Positives: {fp}\")\n",
    "    print(f\"  True Negatives: {tn}\")\n",
    "    print(f\"  False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e71d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze \"no process\" parts\n",
    "no_process_labels = (all_labels.sum(axis=1) == 0).sum()\n",
    "no_process_predictions = (all_predictions.sum(axis=1) == 0).sum()\n",
    "\n",
    "print(f\"\\nParts with no processes:\")\n",
    "print(f\"  Ground truth: {no_process_labels} ({no_process_labels/len(all_labels)*100:.1f}%)\")\n",
    "print(f\"  Predicted: {no_process_predictions} ({no_process_predictions/len(all_predictions)*100:.1f}%)\")\n",
    "\n",
    "# How well does model identify \"no process\" parts?\n",
    "both_empty = ((all_labels.sum(axis=1) == 0) & (all_predictions.sum(axis=1) == 0)).sum()\n",
    "print(f\"  Correctly identified as 'no process': {both_empty}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471eb7d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Re-run evaluation but also collect probabilities\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []  # NEW: collect probabilities\n",
    "threshold = 0.5\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        vec_sets, labels = batch\n",
    "        vec_sets = vec_sets.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(vec_sets)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        predictions = (probs > threshold).float()\n",
    "        \n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_probabilities.append(probs.cpu().numpy())  # NEW\n",
    "\n",
    "# Concatenate\n",
    "all_predictions = np.vstack(all_predictions)\n",
    "all_labels = np.vstack(all_labels)\n",
    "all_probabilities = np.vstack(all_probabilities)  # NEW\n",
    "\n",
    "# Now analyze \"no process\" parts\n",
    "no_proc_indices = np.where(all_labels.sum(axis=1) == 0)[0]\n",
    "print(\"\\nProbabilities for 'no process' parts:\")\n",
    "for i, idx in enumerate(no_proc_indices):\n",
    "    print(f\"Sample {i+1}: {all_probabilities[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001a5db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# SHUFFLE = FALSE FOR REAL NAMES!!!\n",
    "\n",
    "# Get part names from dataset\n",
    "dataset = TKMS_Process_Dataset(mode=\"test\", target_type=\"step-set\")\n",
    "\n",
    "# Map indices to part names\n",
    "no_proc_indices = np.where(all_labels.sum(axis=1) == 0)[0]\n",
    "\n",
    "print(\"\\n'No process' parts with details:\")\n",
    "for i, idx in enumerate(no_proc_indices):\n",
    "    part_name = dataset.samples[idx]  # Get part name from dataset\n",
    "    probs = all_probabilities[idx]\n",
    "    pred = all_predictions[idx]\n",
    "    \n",
    "    print(f\"\\nPart: {part_name}\")\n",
    "    print(f\"  Probabilities: Bohren={probs[0]:.3f}, Drehen={probs[1]:.3f}, Fräsen={probs[2]:.3f}\")\n",
    "    print(f\"  Predicted: {pred}\")\n",
    "    print(f\"  Correct: {'✓' if pred.sum() == 0 else '✗'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
